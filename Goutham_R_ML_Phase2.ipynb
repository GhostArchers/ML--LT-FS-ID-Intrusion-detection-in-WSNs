{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydObQiJ5hwyv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectPercentile, f_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "random_seed = 42\n",
        "np.random.seed(random_seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WTa0bUriiM2_"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/dataset/data.csv\")\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = data[['Area', 'Sensing Range', 'Transmission Range', 'Number of Sensor nodes']]\n",
        "y = data['Number of Barriers']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zG6LoLW4iN2O"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training (75%) and testing (25%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "X_train = X_train.values\n",
        "y_train = y_train.values\n",
        "X_train = X_train.astype(np.float32)\n",
        "y_train = y_train.astype(np.float32)\n",
        "X_test = (X_test.values).astype(np.float32)\n",
        "y_test = (y_test.values).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "F2P4iTBPiSoO"
      },
      "outputs": [],
      "source": [
        "# Perform feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6jfnz2RriYJm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# creating a dictionary to store the results\n",
        "results = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdfA4hn5iYxu",
        "outputId": "2e8d01c5-2f48-47df-8617-117f8ab7843e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8480872892727505\n"
          ]
        }
      ],
      "source": [
        "#Linear regression\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "linearRegression = LinearRegression()\n",
        "\n",
        "linearRegression.fit(X_train_scaled, y_train)\n",
        "\n",
        "r2_Score = linearRegression.score(X_test_scaled, y_test)\n",
        "\n",
        "print(r2_Score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqRoEMQhi250",
        "outputId": "381311df-6b10-41a8-c699-14f46793e42c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial R² Score: 0.5131019684047469\n",
            "Random Search R² Score: 0.9998230015622588\n",
            "Best Parameters from Random Search: {'epsilon': 0.1, 'degree': 5, 'coef0': 2, 'C': 1000}\n"
          ]
        }
      ],
      "source": [
        "# Initialize SVR model with polynomial kernel\n",
        "regressor = SVR(kernel='poly')\n",
        "\n",
        "# Fit the model on the training data\n",
        "regressor.fit(X_train_scaled, y_train)\n",
        "\n",
        "predictions = regressor.predict(X_test_scaled)\n",
        "\n",
        "# Calculating initial R² score\n",
        "r2score = regressor.score(X_test_scaled, y_test)\n",
        "print(f'Initial R² Score: {r2score}')\n",
        "\n",
        "# Parameter grid for Random Search\n",
        "param_dist = {\n",
        "    'C': [0.1, 1, 10, 100,300,500, 1000],\n",
        "    'epsilon': [0.01, 0.1, 0.5, 1, 2, 5],\n",
        "    'degree': [2, 3, 4, 5],\n",
        "    'coef0': [0, 0.1, 0.5, 1, 2]\n",
        "}\n",
        "\n",
        "\n",
        "random_seed = 42\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=SVR(kernel='poly'),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=100,\n",
        "    cv=5,\n",
        "    random_state=random_seed,\n",
        "    n_jobs=-1\n",
        ")\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_random = random_search.best_estimator_.predict(X_test_scaled)\n",
        "\n",
        "# Print R² score of the best estimator from Randomized Search\n",
        "print(f'Random Search R² Score: {r2_score(y_test, y_pred_random)}')\n",
        "print(f'Best Parameters from Random Search: {random_search.best_params_}')\n",
        "\n",
        "#pameter grid for Grid Search\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100,300,500, 1000],\n",
        "    'epsilon': [0.01, 0.1, 0.5, 1, 2, 5],\n",
        "    'degree': [2, 3, 4, 5],\n",
        "    'coef0': [0, 0.1, 0.5, 1, 2]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=SVR(kernel='poly'), param_grid=param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_grid = grid_search.best_estimator_.predict(X_test_scaled)\n",
        "\n",
        "# Print R² score of the best estimator from Grid Search\n",
        "print(f'Grid Search R² Score: {r2_score(y_test, y_pred_grid)}')\n",
        "print(f'Best Parameters from Grid Search: {grid_search.best_params_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIsnh46_i_u8"
      },
      "outputs": [],
      "source": [
        "regressor = SVR(kernel='rbf')\n",
        "\n",
        "# Fit the model on the training data\n",
        "regressor.fit(X_train_scaled, y_train)\n",
        "\n",
        "predictions = regressor.predict(X_test_scaled)\n",
        "\n",
        "# Calculate R² score befire hyp tuning\n",
        "r2score = regressor.score(X_test_scaled, y_test)\n",
        "print(f'Initial R² Score: {r2score}')\n",
        "\n",
        "# Parameter grid for Random Search\n",
        "param_dist = {\n",
        "    'C': [0.1, 1, 10, 100,300,500, 1000],\n",
        "    'epsilon': [0.01, 0.1, 0.5, 1, 2, 5],\n",
        "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1]\n",
        "}\n",
        "\n",
        "random_seed = 42\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=SVR(kernel='rbf'),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=100,\n",
        "    cv=5,\n",
        "    random_state=random_seed,\n",
        "    n_jobs=-1\n",
        ")\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_random = random_search.best_estimator_.predict(X_test_scaled)\n",
        "\n",
        "print(f'Random Search R² Score: {r2_score(y_test, y_pred_random)}')\n",
        "print(f'Best Parameters from Random Search: {random_search.best_params_}')\n",
        "\n",
        "# Parameter grid for Grid Search\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100,300,600, 1000],\n",
        "    'epsilon': [0.01, 0.1, 0.5, 1, 2, 5],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=SVR(kernel='rbf'), param_grid=param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_grid = grid_search.best_estimator_.predict(X_test_scaled)\n",
        "\n",
        "print(f'Grid Search R² Score: {r2_score(y_test, y_pred_grid)}')\n",
        "print(f'Best Parameters from Grid Search: {grid_search.best_params_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ebcaOh7_jh5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd5a0d7-175f-48f0-dd34-1e1eefcd77d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9583936147086227\n",
            "After performing random search\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Search R² Score: 0.9613803439510321\n",
            "Best Parameters: {'splitter': 'random', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 20}\n",
            "\n",
            "after performing grid search\n",
            "Grid Search R² Score: 0.9613803439510321\n",
            "Best Parameters: {'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n"
          ]
        }
      ],
      "source": [
        "#decision tree\n",
        "# Parameter grid for Random Search\n",
        "param_dist = {\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50, 60, 70],\n",
        "    'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'splitter': ['best', 'random']\n",
        "}\n",
        "\n",
        "# Parameter grid for Grid Search\n",
        "param_grid = {\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50, 60, 70],\n",
        "    'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'splitter': ['best', 'random']\n",
        "}\n",
        "\n",
        "#Calculation pre-tuning score\n",
        "regressor = DecisionTreeRegressor(random_state=random_seed)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "predictions = regressor.predict(X_test)\n",
        "r2score = regressor.score(X_test, y_test)\n",
        "print(r2score)\n",
        "\n",
        "#random search\n",
        "print(\"After performing random search\")\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=regressor,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=100,\n",
        "    cv=5,\n",
        "    random_state=random_seed,\n",
        "    n_jobs=-1\n",
        ")\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = random_search.best_estimator_.predict(X_test_scaled)\n",
        "\n",
        "print(f'Random Search R² Score: {r2_score(y_test, y_pred)}')\n",
        "print(f'Best Parameters: {random_search.best_params_}')\n",
        "print(\"\")\n",
        "print(\"after performing grid search\")\n",
        "\n",
        "# Perform Grid Search\n",
        "grid_search = GridSearchCV(estimator=regressor, param_grid=param_grid, cv=5,  n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "best_rf_grid = grid_search.best_estimator_\n",
        "y_pred_grid = best_rf_grid.predict(X_test_scaled)\n",
        "print(f'Grid Search R² Score: {r2_score(y_test, y_pred_grid)}')\n",
        "print(f'Best Parameters: {grid_search.best_params_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qBpAlq7Cjvd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "008ba75b-271b-4575-b717-1547db0f93bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9820857161668751\n",
            "After performing random search\n",
            "Random Search R² Score: 0.984883288772921\n",
            "Best Parameters: {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 1.0, 'max_depth': 40}\n",
            "\n",
            "after performing grid search\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid Search R² Score: 0.9846476026044559\n",
            "Best Parameters: {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n"
          ]
        }
      ],
      "source": [
        "#Random forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "regressor = RandomForestRegressor(random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "predictions = regressor.predict(X_test)\n",
        "\n",
        "r2score = regressor.score(X_test, y_test)\n",
        "print(r2score)\n",
        "print(\"After performing random search\")\n",
        "\n",
        "#Parameter grid for Random Search\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500],\n",
        "    'max_features': [1.0, 'sqrt', 'log2'],\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50, 60, 70],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Parameter grid for Grid Search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300,500],\n",
        "    'max_features': ['auto', 'sqrt'],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=RandomForestRegressor(random_state=random_seed),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=100,\n",
        "    cv=5,\n",
        "    random_state=random_seed,\n",
        "    n_jobs=-1\n",
        ")\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = random_search.best_estimator_.predict(X_test_scaled)\n",
        "\n",
        "print(f'Random Search R² Score: {r2_score(y_test, y_pred)}')\n",
        "print(f'Best Parameters: {random_search.best_params_}')\n",
        "print(\"\")\n",
        "print(\"after performing grid search\")\n",
        "\n",
        "# Perform Grid Search\n",
        "grid_search = GridSearchCV(estimator=regressor, param_grid=param_grid, cv=5,  n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "best_rf_grid = grid_search.best_estimator_\n",
        "y_pred_grid = best_rf_grid.predict(X_test_scaled)\n",
        "print(f'Grid Search R² Score: {r2_score(y_test, y_pred_grid)}')\n",
        "print(f'Best Parameters: {grid_search.best_params_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_tgVeCbkFoB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hN_PxDKuj8bF",
        "outputId": "ffce59de-31f3-4b06-b652-1bc85b8244c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial R² Score: 0.9329108526724954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 25 is smaller than n_iter=100. Running 25 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Search R² Score: 0.9275467183974118\n",
            "Best Parameters from Random Search: {'n_estimators': 50, 'learning_rate': 0.5}\n",
            "Grid Search R² Score: 0.9257789853970088\n",
            "Best Parameters from Grid Search: {'learning_rate': 1.0, 'n_estimators': 100}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Initialize AdaBoost Regressor\n",
        "regressor = AdaBoostRegressor()\n",
        "\n",
        "regressor.fit(X_train_scaled, y_train)\n",
        "\n",
        "predictions = regressor.predict(X_test_scaled)\n",
        "\n",
        "# Calculate initial R² score\n",
        "r2score = regressor.score(X_test_scaled, y_test)\n",
        "print(f'Initial R² Score: {r2score}')\n",
        "\n",
        "# Parameter grid for Random Search\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200, 500, 1000],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0]\n",
        "}\n",
        "\n",
        "random_seed = 42\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=AdaBoostRegressor(),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=100,\n",
        "    cv=5,\n",
        "    random_state=random_seed,\n",
        "    n_jobs=-1\n",
        ")\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_random = random_search.best_estimator_.predict(X_test_scaled)\n",
        "\n",
        "print(f'Random Search R² Score: {r2_score(y_test, y_pred_random)}')\n",
        "print(f'Best Parameters from Random Search: {random_search.best_params_}')\n",
        "\n",
        "# Parameter grid for Grid Search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200, 500, 1000],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0]\n",
        "}\n",
        "\n",
        "# Perform Grid Search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=AdaBoostRegressor(),\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_grid = grid_search.best_estimator_.predict(X_test_scaled)\n",
        "\n",
        "print(f'Grid Search R² Score: {r2_score(y_test, y_pred_grid)}')\n",
        "print(f'Best Parameters from Grid Search: {grid_search.best_params_}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EVxBDYFpkHcU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4a80f5e6-c811-4c72-8773-2a620f32e2ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial R² Score: 0.9874358789970695\n",
            "Random Search R² Score: 0.9940536352256621\n",
            "Best Parameters from Random Search: {'subsample': 0.6, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 3, 'learning_rate': 0.1}\n"
          ]
        }
      ],
      "source": [
        "# Initialize GradientBoostingRegressor model\n",
        "regressor = GradientBoostingRegressor()\n",
        "\n",
        "# Fit the model on the training data\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "predictions = regressor.predict(X_test)\n",
        "\n",
        "# Calculate initial R² score\n",
        "r2score = regressor.score(X_test, y_test)\n",
        "print(f'Initial R² Score: {r2score}')\n",
        "\n",
        "# Parameter grid for Random Search\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200, 500, 1000],\n",
        "    'learning_rate': [0.01, 0.1, 0.05, 0.1, 0.5, 1.0],\n",
        "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4, 6, 8, 10],\n",
        "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "random_seed = 42\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=GradientBoostingRegressor(),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=100,\n",
        "    cv=5,\n",
        "    random_state=random_seed,\n",
        "    n_jobs=-1\n",
        ")\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_random = random_search.best_estimator_.predict(X_test_scaled)\n",
        "\n",
        "print(f'Random Search R² Score: {r2_score(y_test, y_pred_random)}')\n",
        "print(f'Best Parameters from Random Search: {random_search.best_params_}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llubtPkbpFNo"
      },
      "outputs": [],
      "source": [
        "#Phase 1 result\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "models = [\"Linear Regression\", \"SVM (Linear Kernel)\", \"SVM (Polynomial Kernel)\", \"SVM (RBF Kernel)\", \"Decision Tree\", \"Random Forest\", \"AdaBoost\", \"Gradient Boosting\"]\n",
        "scores = [0.848, 0.750, 0.513, 0.289, 0.958, 0.981, 0.938, 0.987]\n",
        "\n",
        "# Plotting the bar graph\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.bar(models, scores, color='orange')\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('R² Score')\n",
        "plt.title('Regression model comparision')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bX5cYSWcNYJP"
      },
      "outputs": [],
      "source": [
        "#Visualisation after performing hyperparameter tuning\n",
        "\n",
        "#feeding the datsets for the plot\n",
        "models = [\"SVM (Polynomial)\", \"SVM (RBF Kernel)\", \"Decision Tree\", \"Random Forest\", \"AdaBoost\", \"Gradient Boosting\"]\n",
        "r2_scores_before = [0.513, 0.289, 0.958, 0.981, 0.938, 0.987]\n",
        "r2_scores_after = [0.999, 0.999, 0.961, 0.984, 0.929, 0.995]\n",
        "\n",
        "# Defining the positions and width for the bars\n",
        "x = np.arange(len(models))\n",
        "width = 0.3\n",
        "\n",
        "plt.style.use('seaborn-darkgrid')\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "rects1 = ax.bar(x - width/2, r2_scores_before, width, label='Before Tuning', color='mediumpurple')\n",
        "rects2 = ax.bar(x + width/2, r2_scores_after, width, label='After Tuning', color='darkorange')\n",
        "\n",
        "# Adding labels and other charecterstrics\n",
        "ax.set_xlabel('Model', fontsize=12)\n",
        "ax.set_ylabel('R² Score', fontsize=12)\n",
        "ax.set_title('R² Scores Before and After Hyperparameter Tuning', fontsize=14)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(models, rotation=45, ha='right', fontsize=10)\n",
        "ax.legend(loc='best')\n",
        "ax.bar_label(rects1, padding=3, fmt='%.3f')\n",
        "ax.bar_label(rects2, padding=3, fmt='%.3f')\n",
        "\n",
        "ax.set_ylim(0, 1.1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6stL0JH8c7i5"
      },
      "outputs": [],
      "source": [
        "#Applying tsne\n",
        "\n",
        "tsne = TSNE(n_components=2, init='pca', learning_rate='auto', random_state=42)\n",
        "tsne_results = tsne.fit_transform(X_scaled)\n",
        "\n",
        "tsne_df = pd.DataFrame(tsne_results, columns=['TSNE1', 'TSNE2'])\n",
        "tsne_df['Number of Barriers'] = y\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "scatter = plt.scatter(tsne_df['TSNE1'], tsne_df['TSNE2'], c=tsne_df['Number of Barriers'], cmap='viridis', alpha=0.7)\n",
        "colorbar = plt.colorbar(scatter)\n",
        "colorbar.set_label('Number of Barriers')\n",
        "plt.title('2D Visualization of Data using t-SNE')\n",
        "plt.xlabel('TSNE1')\n",
        "plt.ylabel('TSNE2')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trd0kYGwieMP"
      },
      "outputs": [],
      "source": [
        "#Feature selection\n",
        "\n",
        "from sklearn.feature_selection import SelectPercentile, f_regression\n",
        "\n",
        "feature_selection = SelectPercentile(score_func=f_regression, percentile=50)\n",
        "X_train_scaled_feature_selection = feature_selection.fit_transform(X_train_scaled, y_train)\n",
        "X_test_scaled_feature_selection = feature_selection.transform(X_test_scaled)\n",
        "\n",
        "selected_feature_indices = feature_selection.get_support(indices=True)\n",
        "\n",
        "\n",
        "feature_names = np.array(['Area','Sensing rane', 'transmission range', 'number of sensors'])\n",
        "\n",
        "# Get the selected feature names\n",
        "selected_feature_names = feature_names[selected_feature_indices]\n",
        "\n",
        "print(\"Selected feature names:\")\n",
        "print(selected_feature_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the best model with selected features\n",
        "gb = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "gb.fit(X_train_scaled_feature_selection, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = gb.predict(X_test_scaled_feature_selection)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"R² Score with selected features: {r2}\")"
      ],
      "metadata": {
        "id": "zXMmkF4sjo5w"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}